{
    "lora_scaling_rank": 1,
    "lora_rank": 0,
    "lora_init_scale": 0.0,
    "lora_modules": ".*SelfAttention|.*EncDecAttention|.*DenseReluDense",
    "lora_layers": "k|v|wi_1.*",
    "trainable_param_names": ".*weight_leafs*",
    "model_modifier": "lora",
    "lr": 3e-3,
    "num_steps": 1000,
    "eval_epoch_interval": 50,
    "order": 2,
    "core": "emb2ket"
}